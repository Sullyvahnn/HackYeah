#!/usr/bin/env python3
"""
Skrypt testowy dla Cyklu 1: Scrapowanie i Filtracja
Uruchom z folderu src/: python test_cycle1.py
"""

import os
import sys

# Dodaj src/ do PYTHONPATH
sys.path.insert(0, os.path.dirname(__file__))

def test_database():
    """Test 1: SprawdÅº czy baza danych dziaÅ‚a"""
    print("="*60)
    print("TEST 1: Inicjalizacja bazy danych")
    print("="*60)
    
    from agent.db import initialize_db_manager
    
    db_manager = initialize_db_manager('data/crime_data.db')
    stats = db_manager.get_statistics()
    
    print(f"âœ… Baza danych dziaÅ‚a!")
    print(f"   Wszystkie artykuÅ‚y: {stats['total_articles']}")
    print(f"   Przetworzone: {stats['processed']}")
    print(f"   OczekujÄ…ce: {stats['pending']}")
    print()
    
    return db_manager

def test_ai_filter():
    """Test 2: SprawdÅº czy filtr AI dziaÅ‚a"""
    print("="*60)
    print("TEST 2: Filtr AI")
    print("="*60)
    
    from agent.crime_news_scrapper.ai_filter import CrimeFilter
    
    print("ÅadujÄ™ model AI...")
    filter_ai = CrimeFilter()
    
    # Testowe artykuÅ‚y
    test_cases = [
        ("ZÅ‚odziej ukradÅ‚ samochÃ³d na ulicy DÅ‚ugiej w Krakowie", True),
        ("Pogoda na weekend: ciepÅ‚o i sÅ‚onecznie", False),
        ("Policja zatrzymaÅ‚a sprawcÄ™ rozboju w centrum miasta", True),
        ("Nowy salon piÄ™knoÅ›ci otwarto na Rynku", False),
    ]
    
    print("\nğŸ§ª TestujÄ™ klasyfikacjÄ™:\n")
    for title, expected in test_cases:
        result = filter_ai.is_crime_related(title)
        status = "âœ…" if result == expected else "âŒ"
        print(f"{status} '{title[:50]}...' â†’ {result}")
    
    print()
    return filter_ai

def run_spider():
    """Test 3: Uruchom spider"""
    print("="*60)
    print("TEST 3: Uruchomienie Spider")
    print("="*60)
    print("Uruchamiam scrapy spider...")
    print("UWAGA: To moÅ¼e potrwaÄ‡ kilka minut!\n")
    
    # Uruchom scrapy z linii komend
    os.system("cd src && scrapy crawl crime_news -s CLOSESPIDER_PAGECOUNT=3")

def check_results(db_manager):
    """Test 4: SprawdÅº zapisane artykuÅ‚y"""
    print("\n" + "="*60)
    print("TEST 4: Wyniki w bazie danych")
    print("="*60)
    
    stats = db_manager.get_statistics()
    print(f"ğŸ“Š Statystyki:")
    print(f"   Wszystkie artykuÅ‚y: {stats['total_articles']}")
    print(f"   Przetworzone: {stats['processed']}")
    print(f"   OczekujÄ…ce na AI: {stats['pending']}")
    
    # PokaÅ¼ przykÅ‚adowe artykuÅ‚y
    unprocessed = db_manager.get_unprocessed_articles(limit=5)
    
    if unprocessed:
        print(f"\nğŸ“° PrzykÅ‚adowe artykuÅ‚y do przetworzenia:\n")
        for i, article in enumerate(unprocessed, 1):
            print(f"{i}. [{article['source']}] {article['title']}")
            print(f"   DÅ‚ugoÅ›Ä‡ tekstu: {len(article['raw_text'])} znakÃ³w")
            print(f"   URL: {article['url'][:80]}...")
            print()
    else:
        print("\nâš ï¸ Brak nieprzetworzonych artykuÅ‚Ã³w w bazie!")
    
    print("="*60)

if __name__ == "__main__":
    print("\nğŸš€ URUCHAMIAM TESTY CYKLU 1\n")
    
    try:
        # Test 1: Baza danych
        db_manager = test_database()
        
        # Test 2: Filtr AI
        test_ai_filter()
        
        # Test 3: Spider (moÅ¼na pominÄ…Ä‡ dla szybkiego testu)
        response = input("Czy uruchomiÄ‡ spider? (moÅ¼e potrwaÄ‡ ~2-3 min) [t/N]: ")
        if response.lower() == 't':
            run_spider()
            
            # Test 4: Wyniki
            check_results(db_manager)
        else:
            print("\nâ­ï¸ Pomijam uruchomienie spider")
            print("ğŸ’¡ Aby uruchomiÄ‡ rÄ™cznie: cd src && scrapy crawl crime_news")
        
        print("\nâœ… TESTY ZAKOÅƒCZONE!")
        
    except Exception as e:
        print(f"\nâŒ BÅÄ„D: {e}")
        import traceback
        traceback.print_exc()