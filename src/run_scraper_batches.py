#!/usr/bin/env python3
"""
Uruchamia scrapy w partiach z przerwami
Bezpiecznie wykorzystuje limit 30 req/min przez dÅ‚uÅ¼szy czas
"""

import subprocess
import time
import logging
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BatchScraper:
    def __init__(self, duration_minutes=20, batch_items=5, pause_seconds=65):
        """
        Args:
            duration_minutes: Ile minut ma dziaÅ‚aÄ‡ (np. 20)
            batch_items: Ile artykuÅ‚Ã³w na batch (np. 5)
            pause_seconds: Ile sekund przerwy (np. 65 = bezpieczne)
        """
        self.duration = duration_minutes * 60  # konwersja na sekundy
        self.batch_items = batch_items
        self.pause = pause_seconds
        
        self.total_items = 0
        self.total_batches = 0
        self.start_time = time.time()

    def run_single_batch(self):
        """Uruchamia jeden batch scrapera"""
        self.total_batches += 1
        
        logger.info("=" * 70)
        logger.info(f"ğŸš€ BATCH #{self.total_batches} - Cel: {self.batch_items} artykuÅ‚Ã³w")
        logger.info("=" * 70)
        
        try:
            # Uruchom scrapy z limitem artykuÅ‚Ã³w
            cmd = [
                "scrapy", "runspider",
                "agent/crime_news_scrapper/krakow_crime_spider.py",
                "-s", f"CLOSESPIDER_ITEMCOUNT={self.batch_items}",
                "-s", "CLOSESPIDER_PAGECOUNT=10",  # Max 10 stron na batch
                "-s", "LOG_LEVEL=INFO"
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5 min max na batch
            )
            
            # Policz zebrane artykuÅ‚y z outputu
            output = result.stdout + result.stderr
            saved = output.count("âœ… [")  # Licznik z logÃ³w
            self.total_items += saved
            
            logger.info(f"âœ… Batch zakoÅ„czony: zebrano {saved} artykuÅ‚Ã³w")
            logger.info(f"ğŸ“Š TOTAL: {self.total_items} artykuÅ‚Ã³w w {self.total_batches} batchach")
            
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("â±ï¸ Timeout - batch trwaÅ‚ za dÅ‚ugo!")
            return False
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d: {e}")
            return False

    def run(self):
        """GÅ‚Ã³wna pÄ™tla - uruchamia batche przez okreÅ›lony czas"""
        logger.info("ğŸ¯ START BATCH SCRAPERA")
        logger.info(f"â±ï¸  Czas dziaÅ‚ania: {self.duration/60:.0f} minut")
        logger.info(f"ğŸ“¦ ArtykuÅ‚Ã³w na batch: {self.batch_items}")
        logger.info(f"â¸ï¸  Pauza miÄ™dzy batchami: {self.pause}s")
        logger.info("=" * 70)
        
        while True:
            elapsed = time.time() - self.start_time
            
            # SprawdÅº czy czas siÄ™ skoÅ„czyÅ‚
            if elapsed >= self.duration:
                logger.info("=" * 70)
                logger.info("ğŸ KONIEC - OsiÄ…gniÄ™to limit czasu")
                break
            
            remaining = self.duration - elapsed
            logger.info(f"â° PozostaÅ‚o: {remaining/60:.1f} min")
            
            # Uruchom batch
            success = self.run_single_batch()
            
            if not success:
                logger.warning("âš ï¸  Batch nieudany, ale kontynuujÄ™...")
            
            # SprawdÅº czy starczy czasu na nastÄ™pny batch
            if remaining < self.pause + 120:  # 120s = czas na batch
                logger.info("â±ï¸  Za maÅ‚o czasu na kolejny batch")
                break
            
            # Pauza przed nastÄ™pnym batchem
            logger.info(f"ğŸ’¤ Pauza {self.pause}s (reset limitu API)...")
            logger.info("")
            time.sleep(self.pause)
        
        # Podsumowanie
        self.print_summary()

    def print_summary(self):
        """WyÅ›wietla podsumowanie"""
        elapsed = time.time() - self.start_time
        
        logger.info("")
        logger.info("=" * 70)
        logger.info("ğŸ“Š PODSUMOWANIE")
        logger.info("=" * 70)
        logger.info(f"â±ï¸  Czas dziaÅ‚ania: {elapsed/60:.1f} minut")
        logger.info(f"ğŸ“¦ Uruchomionych batchy: {self.total_batches}")
        logger.info(f"ğŸ“° Zebranych artykuÅ‚Ã³w: {self.total_items}")
        
        if self.total_batches > 0:
            avg = self.total_items / self.total_batches
            logger.info(f"ğŸ“ˆ Åšrednio na batch: {avg:.1f} artykuÅ‚Ã³w")
        
        logger.info("=" * 70)
        logger.info(f"âœ… Dane zapisane w: data/krakow/events_{datetime.now().date()}.jsonl")
        logger.info(f"âœ… Baza danych: data/crime_data.db")
        logger.info("=" * 70)


def main():
    """
    PrzykÅ‚adowe konfiguracje:
    
    # Konserwatywna (20 min, maÅ‚e batche):
    scraper = BatchScraper(duration_minutes=20, batch_items=3, pause_seconds=70)
    
    # Standardowa (20 min, Å›rednie batche):
    scraper = BatchScraper(duration_minutes=20, batch_items=5, pause_seconds=65)
    
    # Agresywna (30 min, wiÄ™ksze batche):
    scraper = BatchScraper(duration_minutes=30, batch_items=8, pause_seconds=65)
    """
    
    # ğŸ¯ TWOJA KONFIGURACJA:
    scraper = BatchScraper(
        duration_minutes=20,   # 20 minut dziaÅ‚ania
        batch_items=5,         # 5 artykuÅ‚Ã³w na batch
        pause_seconds=65       # 65s pauzy (bezpieczne)
    )
    
    try:
        scraper.run()
    except KeyboardInterrupt:
        logger.info("\nâ›” Przerwano przez uÅ¼ytkownika (Ctrl+C)")
        scraper.print_summary()


if __name__ == "__main__":
    main()